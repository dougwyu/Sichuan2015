---
title: "2015_Sichuan_MBC"
output: html_document
---

```{r setup, test methods}
##### make sure that Source option is set to `Chunk output in Console` and do not select `Show Previews inline`

# add packages that I will use
library(tidyverse) # includes all data-formatting packages as one big package (e.g. dplyr, tidyr, ggplot2, readr, readxl, tibble, and others)
# library(broom)
library(vegan)
library(iNEXT)
# library(car)
# library(breakaway)
library(boral)
library(mvabund)
sessionInfo()
```

```{r load and format data}
inputfile <- "data/Sichuan2015_OTU_LerayCOI_DAMe_min1PCR_min20copies_sumaclust97.txt"
habitatinput <- "data/habitat.txt"

# help(read_tsv)
# command from readr package, and you tell the command how to format the columns
gfgMB <- read_tsv(inputfile, col_names = TRUE, na = "NA") %>% tbl_df() # convert to tibble format
# gfgMB is a convenient variable name that stands for Grain for Green MetaBarcoding

habitat <- read_tsv(habitatinput, 
	col_names = TRUE, na = "NA", 
	col_types = cols(
	  PlotID = col_character(),
	  Region = col_character(),
	  Location = col_character(),
	  TreeCover = col_integer(),
	  Clumpedness = col_integer()
		)
	)
```

```{r community dataset}
# make community dataset:  Columns are species (OTUs) and rows are samples (sites). This requires transposing the dataset and then doing a bunch of formatting to restore column names and formatting
community <- gfgMB
community_t <- t(community)
community_t <- as.data.frame(community_t)
colvector <- t(community[, 1]) # all rows, column 1
colnames(community_t) <- colvector # add column names
community_t <- community_t[-1, ] # remove row 1
# community_t <- rownames_to_column(community_t)

# convert the columns to numeric from factor
# http://stackoverflow.com/questions/2288485/how-to-convert-a-data-frame-column-to-numeric-type
community_t <- sapply(community_t, function(x) as.numeric(as.character(x))) # sapply applies a function to each column, and the function is:  function(x) as.numeric(as.character(x)).  Cannot convert factors to numeric directly. first convert to character, then to numeric
community_t <- as.data.frame(community_t) # then convert to df
```

```{r remove pos ctrl OTUs}
colSums(community_t) # some colSums = 0 because these were OTUS from the positive control samples (and thus not species that exist in the real samples)

community_t <- community_t[ , which(colSums(community_t) > 0)] # omit OTUs that have no reads
colSums(community_t) # all OTUs have some reads
rowSums(community_t) # all sites have some OTUs
```


```{r choose commmunity to analyse}

# this is code that i can use to change the name of the community dataset and the habitat dataset, allowing me to write more general code below. in this case, just run these lines, and the community and habitat datasets will be referred to as comunity_now and habitat_now

community_name <- deparse(substitute(community_t)) # put name of community here
habitat_now <- habitat # change this if i want to change which habitat dataset i'm working with
community_now <- get(community_name)
```

```{r save datasets for later alpha diversity analyses}
community_sngltons <-  community_now
habitat_sngltons <- habitat_now
```



# Beta diversity analyses:  does arthropod community composition differ?  The answer is yes, but we don't know why yet.
```{r remove singleton OTUs for beta diversity analyses}
# omit OTUs that appear in only one row (site)
community_now_nosngltons <- community_now %>% select_if(specnumber(community_now, MARGIN = 2) > 1) # remove singleton OTUs (found in only one site) specnumber(MARGIN = 2) counts the number of sites that have a particular OTU. (same as colSums > 2)
rowSums(community_now_nosngltons) 
# remove any rows (sites) with no species
	# first use the community table to alter the habitat table
habitat_now_nosngltons <- habitat_now[which(rowSums(community_now_nosngltons) > 0), ]
	# then alter the community tables
community_now_nosngltons <- community_now_nosngltons[which(rowSums(community_now_nosngltons) >0), ]
rowSums(community_now_nosngltons)
community_now <- community_now_nosngltons
```

visualise a histogram of read number per OTU
```{r histogram of otu read numbers}
##### calculate distribution of read numbers per OTU to set minimum number 
otureads <- c(colSums(community_now)) # list of the reads per OTU
sum(otureads) ## 1,086,199 reads total (this is after removing some of the sites, so this is almost but not all the reads in the original dataset)
otureads[otureads>5000] <- 5000 # to make the histogram readable
otuhist <- hist(otureads, breaks = 100)
text(otuhist$mids, otuhist$counts, cex = 0.5, otuhist$counts, adj = c(.5, -.5), col = "blue3")
```


```{r}
# vegemite(community_now)
dca <- decorana(community_now)
# vegemite(community_now, dca, "Hill")

plotree <- hclust(vegdist(community_now), "average")
tabasco(community_now, plotree)

# clear turnover of species across sites.  our question is what causes this turnover
```


```{r nmds}
# do NMDS analysis to see basic patterns #
community.jmds <- metaMDS(community_now, distance = "jaccard", trymax = 40, binary = FALSE)
community.jmds <- metaMDS(community_now, distance = "jaccard", binary = FALSE, previous.best = community.jmds)

stressplot(community.jmds)
```

```{r plot nmds}
#### plot the communities.  Basically, there's no useful environmental predictor in this habitat file (tree clumpedness and tree cover). the hope is that the new environmental predictors will provide more explanatory power
#### 

# What we are looking for here is for large circles to be in one region of the figure and small circles in another. The circle sizes are related various ways of measuring the environmental variables:  Clumpedness and TreeCover.  In other words, we want to see if insect communities in high Clumpedness/TreeCover sites are different (in different parts of the NMDS) from low Clumpedness/TreeCover sites

(sprichness <- specnumber(community_now, MARGIN = 1)) # number of species per site

with(habitat_now, ordisurf(community.jmds, sprichness, main=community_name, cex=Clumpedness*TreeCover/20))

with(habitat_now, ordisurf(community.jmds, TreeCover, main=community_name, cex=TreeCover/5))

with(habitat_now, ordisurf(community.jmds, Clumpedness, main=community_name, cex=Clumpedness))

with(habitat_now, ordispider(community.jmds, Region, main=community_name, cex=0.5))

with(habitat_now, ordiellipse(community.jmds, Region, cex=.5, draw="polygon", col=c("blue"), alpha=20, kind="se", conf=0.95, label=TRUE))

```


# these are optional commands to allow individual identification of points
```{r ordiplots, eval = FALSE}
# These commands are ways to identify points
orditorp(community.jmds, labels = habitat_now$Site, dis="sites", pcol = "gray")

ordipointlabel(community.jmds, dis="sites")

p1 <- plot(community.jmds, dis="sites")
identify(p1, "sites") # interactive method to identify sites by row number. Click on the points that you want to identify. When you have clicked on all the points, click on the Finish button at top right of Plot window. 
```



#### Alpha diversity:  does arthropod species diversity or richness across sites?  The answer is yes, but we don't know why yet.

We use the habitat_sngltons and community_sngltons datasets because alpha diversity analyses require knowing the species that occur in only one sample.  The intuition is that many of the species that you collect are only collected once (singletons), then you probably have a highly diverse species pool out there. 

```{r t.test2}
############ This function (t.test2) will calculate Welch's test
t.test2 <- function(m1, m2, s1, s2, n1, n2, m0=0, equal.variance=FALSE)
{
  if( equal.variance==FALSE ) 
  {
    se <- sqrt( (s1^2/n1) + (s2^2/n2) )
    # welch-satterthwaite df
    df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
  } else
  {
    # pooled standard deviation, scaled by the sample sizes
    se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) ) 
    df <- n1+n2-2
  }      
  t <- (m1-m2-m0)/se 
  dat <- c(m1-m2, se, t, round(df,1), 2*pt(-abs(t),df))    
  names(dat) <- c("Difference of means", "Std Error", "t", "df", "p-value")
  return(dat) 
}
```



```{r specpool}
# IMPORTANT:  Only use OTU tables that still have singleton OTUs, because singleton OTUs are needed for chao stats

pool1 <- specpool(community_sngltons)
pool1

pool2 <- specpool(community_sngltons, habitat_sngltons$Region)
pool2

# example pairwise comparison:  chao, Mianzhu vs Qionglai
# t.test2(m1, m2, s1, s2, n1, n2, m0=0)
# s1 and s2 are standard deviations, but specpool returns standard errors of the mean, which is sd/sqrt(n), so i need to multiply by sqrt(n) to get back sd
t.test2(pool2[1, 2], pool2[2, 2], pool2[1, 3]*sqrt(pool2[1, 9]), pool2[2, 3]*sqrt(pool2[2, 9]), pool2[1, 9], pool2[2, 9])

```


# calculate Shannon diversity instead of just species richness, mean for each Region
```{r shannon diversity}
community_sngltons %>% dplyr::filter(habitat_sngltons$Region == "Mianzhu") %>% diversity(index = "shannon") %>% mean()
community_sngltons %>% filter(habitat_sngltons$Region == "Qionglai") %>% diversity(index = "shannon") %>% mean()
community_sngltons %>% filter(habitat_sngltons$Region == "Xiushuizhen") %>% diversity(index = "shannon") %>% mean()
```


```{r iNEXT}
# # vignette ("Introduction", package="iNEXT")
# # http://chao.stat.nthu.edu.tw/wordpress/wp-content/uploads/software/iNEXT_UserGuide.pdf
# # example for incidence based data 
# data(ant)
# str(ant)
# t <- seq(1, 700, by=10)
# out.inc <- iNEXT(ant, q=0, datatype="incidence_freq", size=t)
# ggiNEXT(out.inc, type = 1)
# out.inc$DataInfo

community_sngltons_incidence <- community_sngltons
community_sngltons_incidence[community_sngltons_incidence > 0] <- 1  # change all numbers > 0 to 1

Mianzhu <- community_sngltons_incidence %>% dplyr::filter(habitat_sngltons$Region == "Mianzhu") 
Qionglai <- community_sngltons_incidence %>% dplyr::filter(habitat_sngltons$Region == "Qionglai")
Xiushuizhen <- community_sngltons_incidence %>% dplyr::filter(habitat_sngltons$Region == "Mianzhu") 

cname <- c("Mianzhu", "Qionglai", "Xiushuizhen")

comm4inext <- matrix(c(colSums(Mianzhu), colSums(Qionglai), colSums(Xiushuizhen)), ncol = 3)
colnames(comm4inext) <- cname # add column names
comm4inext <- rbind(c(nrow(Mianzhu), nrow(Qionglai), nrow(Xiushuizhen)), comm4inext) # add max number of sites for each column

# the dataset structure:  each row is a species except for the first row.  each column is a sampled area (e.g. Mianzhu). the first row is the total number of sites that were sampled in each area (e.g. n = 8 sites sampled within Mianzhu region). The other rows are the species, and the number is the number of sites in which that species is found. For example, row 2, column 1 is the first species in Mianzhu, and it is found in 8 of the 8 sites. Note that all numbers under row 1 cannot be larger than the number in row 1


confnum=0.95 # set confidence here
outcomm0 <- iNEXT(comm4inext, q=0, conf=confnum, datatype="incidence_freq")
ggiNEXT(outcomm0, type=1)  # Qionglai is slightly more species rich but appears not to be significantly different
# Hill numbers:  0 = sp richness, 1 = Shannon, 2 = inverse Simpson
outcomm0$DataInfo
ChaoRichness(comm4inext, datatype="incidence_freq") # same as specpool results, so i trust that we have done this correctly. Compare to this line
specpool(community_sngltons, habitat_sngltons$Region)

# calculate Shannon diversity for each region
ChaoShannon(comm4inext, datatype="incidence_freq")

outcomm1 <- iNEXT(comm4inext, q=1, conf=confnum, datatype="incidence_freq")
outcomm2 <- iNEXT(comm4inext, q=2, conf=confnum, datatype="incidence_freq")

ggiNEXT(outcomm0, type=1) # sample-size-based rarefaction/extrapolation curve:  species richness
ggiNEXT(outcomm1, type=1) # sample-size-based rarefaction/extrapolation curve:  Shannon
ggiNEXT(outcomm2, type=1) # sample-size-based rarefaction/extrapolation curve:  Simpson

ggiNEXT(outcomm0, type=2) # sample completeness curve
ggiNEXT(outcomm0, type=3) # coverage-based rarefaction/extrapolation curve

# outcomm0$DataInfo
# outcomm0$iNextEst
# outcomm0$AsyEst
```


#### Below this is code from a different dataset that i use as model code for more complex analyses.  you can ignore this stuff. 

```{r boral, eval=FALSE}
colnames(community_now) <- c(1:ncol(community_now)) # change colnames to a simple number
community_now[community_now > 1] <-  1 # change to presence/absence

# set up MCMC parameters 
#mcmc.control <- list(n.burnin = 100, n.iteration = 1000, n.thin = 10)
mcmc.control <- list(n.burnin = 10000, n.iteration = 40000, n.thin = 30)

# Set up priors
# Francis Hui suggests trying different priors to stabilise sampling for sparse matrices (such as we have).  This isn't as important as getting the mcmc.control parameters right
set.prior <- list(type = c("normal","normal","normal","uniform"), hypparams = c(10, 10, 10, 30)) # boral default
# set.prior <- list(type = c("normal","normal","normal","uniform"), hypparams = c(10, 10, 10, 30), ssvs.index = ssvsindex)  
# type = c("cauchy","cauchy","cauchy","uniform"), hypparams = c(2.5^2, 2.5^2, 2.5^2, 30) # Gelman proposed this
# type = c("normal","normal","normal","uniform"), hypparams = c(1, 1, 1, 30) ## People who developed the STAN package proposed this as one possibility. 

# set up model
comm.fit.b1 <- boral(community_now, family = "binomial", num.lv = 2, row.eff = "random", calc.ics = FALSE, mcmc.control = mcmc.control)
summary(comm.fit.b1)
par(mfrow = c(2,2))
plot(comm.fit.b1) ## Plots used in residual analysis, 
par(mfrow = c(1,1))
lvsplot(comm.fit.b1, biplot = FALSE, jitter = TRUE, col = as.numeric(habitat_now$Region))
```


http://www.wcsmalaysia.org/analysis/Biod_richness.htm

#### mvabund analysis

```{r mvabund}
community_now_mva<-mvabund(community_now) # convert the arthropods dataset to mvabund format
is.mvabund(community_now_mva) # checking that the arthmvabund dataset is properly formatted
meanvar.plot(community_now_mva)
plot(community_now_mva ~ habitat_now$Habitat) # predictor must be a factor ~ habitat_now$habitat) 
```

```{r mvabund model}
comm.nb <- manyglm(community_now_mva ~ habitat_now$Habitat, family="negative.binomial") # alternatives are:  binomial, binomial(link="cloglog"), poisson
```

```{r residuals pit.norm}
plot(comm.nb, res.type="pit.norm") # residuals vs fitted, pretty good
```

```{r residuals pit.uniform}
plot(comm.nb, res.type="pit.uniform") # residuals vs fitted, pretty good
```

```{r anova manyglm}
community_now_mva.anova <- anova(comm.nb, p.uni="adjusted", test="wald", resamp="pit.trap", nBoot=10, show.time="all")  # nBoot=10 requires ~2.3 mins, time scales linearly with nBoot
```

```{r mvabund anova p-values table}
community_now_mva.anova$table
```

The next thing is to compare all habitats against NF (Natural Forest). To do this, we need to make a bunch of pairwise community_now and habitat_now datasets (here, 5) and do anovas. Afterwards, we make a vector of all the p-values and correct them for the 5 tests that we did.

```{r}
nboot <- 10
```

```{r pairwise mvabund NF vs MF}
habitat_now_NF_MF <- habitat_now %>% filter(Habitat %in% c("NF", "MF"))
community_now_NF_MF <- community_now %>% filter(habitat_now$Habitat %in%  c("NF", "MF"))
community_now_NF_MF <- community_now_NF_MF %>% select_if(specnumber(community_now_NF_MF, MARGIN = 2) > 0) # keep only OTUs that appear in more than one site.
# community_now_NF_MF <- community_now_NF_MF[, colSums(community_now_NF_MF) >= 50] # alternative filtering:  remove OTUs that have fewer than, here, 50 reads, which keeps singleton OTUs in
community_now_NF_MF_mva <- mvabund(community_now_NF_MF)
is.mvabund(community_now_NF_MF_mva)
comm_NF_MF.nb <- manyglm(community_now_NF_MF_mva ~ habitat_now_NF_MF$Habitat, family="negative.binomial")
plot(comm_NF_MF.nb, res.type="pit.norm")
community_now_NF_MF_mva.anova <- anova(comm_NF_MF.nb, p.uni="adjusted", test="wald", resamp="pit.trap", nBoot=nboot, show.time="all") 
community_now_NF_MF_mva.anova$table
```

```{r pairwise mvabund NF vs BB}
habitat_now_NF_BB <- habitat_now %>% filter(Habitat %in% c("NF", "BB"))
community_now_NF_BB <- community_now %>% filter(habitat_now$Habitat %in%  c("NF", "BB"))
community_now_NF_BB <- community_now_NF_BB %>% select_if(specnumber(community_now_NF_BB, MARGIN = 2) > 0) # keep only OTUs that appear in more than one site.
# community_now_NF_BB <- community_now_NF_BB[, colSums(community_now_NF_BB) >= 50] # alternative filtering:  remove OTUs that have fewer than, here, 50 reads, which keeps singleton OTUs in
community_now_NF_BB_mva <- mvabund(community_now_NF_BB)
is.mvabund(community_now_NF_BB_mva)
comm_NF_BB.nb <- manyglm(community_now_NF_BB_mva ~ habitat_now_NF_BB$Habitat, family="negative.binomial")
plot(comm_NF_BB.nb, res.type="pit.norm")
community_now_NF_BB_mva.anova <- anova(comm_NF_BB.nb, p.uni="adjusted", test="wald", resamp="pit.trap", nBoot=nboot, show.time="all") 
community_now_NF_BB_mva.anova$table
```

```{r pairwise mvabund NF vs JC}
habitat_now_NF_JC <- habitat_now %>% filter(Habitat %in% c("NF", "JC"))
community_now_NF_JC <- community_now %>% filter(habitat_now$Habitat %in%  c("NF", "JC"))
community_now_NF_JC <- community_now_NF_JC %>% select_if(specnumber(community_now_NF_JC, MARGIN = 2) > 0) # keep only OTUs that appear in more than one site.
# community_now_NF_JC <- community_now_NF_JC[, colSums(community_now_NF_JC) >= 50] # alternative filtering:  remove OTUs that have fewer than, here, 50 reads, which keeps singleton OTUs in
community_now_NF_JC_mva <- mvabund(community_now_NF_JC)
is.mvabund(community_now_NF_JC_mva)
comm_NF_JC.nb <- manyglm(community_now_NF_JC_mva ~ habitat_now_NF_JC$Habitat, family="negative.binomial")
plot(comm_NF_JC.nb, res.type="pit.norm")
community_now_NF_JC_mva.anova <- anova(comm_NF_JC.nb, p.uni="adjusted", test="wald", resamp="pit.trap", nBoot=nboot, show.time="all") 
community_now_NF_JC_mva.anova$table
```

```{r pairwise mvabund NF vs EC}
habitat_now_NF_EC <- habitat_now %>% filter(Habitat %in% c("NF", "EC"))
community_now_NF_EC <- community_now %>% filter(habitat_now$Habitat %in%  c("NF", "EC"))
community_now_NF_EC <- community_now_NF_EC %>% select_if(specnumber(community_now_NF_EC, MARGIN = 2) > 0) # keep only OTUs that appear in more than one site.
# community_now_NF_EC <- community_now_NF_EC[, colSums(community_now_NF_EC) >= 50] # alternative filtering:  remove OTUs that have fewer than, here, 50 reads, which keeps singleton OTUs in
community_now_NF_EC_mva <- mvabund(community_now_NF_EC)
is.mvabund(community_now_NF_EC_mva)
comm_NF_EC.nb <- manyglm(community_now_NF_EC_mva ~ habitat_now_NF_EC$Habitat, family="negative.binomial")
plot(comm_NF_EC.nb, res.type="pit.norm")
community_now_NF_EC_mva.anova <- anova(comm_NF_EC.nb, p.uni="adjusted", test="wald", resamp="pit.trap", nBoot=nboot, show.time="all") 
community_now_NF_EC_mva.anova$table
```

```{r pairwise mvabund NF vs CL}
habitat_now_NF_CL <- habitat_now %>% filter(Habitat %in% c("NF", "CL"))
community_now_NF_CL <- community_now %>% filter(habitat_now$Habitat %in%  c("NF", "CL"))
community_now_NF_CL <- community_now_NF_CL %>% select_if(specnumber(community_now_NF_CL, MARGIN = 2) > 0) # keep only OTUs that appear in more than one site.
# community_now_NF_CL <- community_now_NF_CL[, colSums(community_now_NF_CL) >= 50] # alternative filtering:  remove OTUs that have fewer than, here, 50 reads, which keeps singleton OTUs in
community_now_NF_CL_mva <- mvabund(community_now_NF_CL)
is.mvabund(community_now_NF_CL_mva)
comm_NF_CL.nb <- manyglm(community_now_NF_CL_mva ~ habitat_now_NF_CL$Habitat, family="negative.binomial")
plot(comm_NF_CL.nb, res.type="pit.norm")
community_now_NF_CL_mva.anova <- anova(comm_NF_CL.nb, p.uni="adjusted", test="wald", resamp="pit.trap", nBoot=nboot, show.time="all") 
community_now_NF_CL_mva.anova$table
```

```{r pvalues list}
pvalues <- c(community_now_NF_MF_mva.anova$table[2,4], community_now_NF_BB_mva.anova$table[2,4], community_now_NF_JC_mva.anova$table[2,4], community_now_NF_EC_mva.anova$table[2,4], community_now_NF_CL_mva.anova$table[2,4])
pvalues
```

```{r fdr correction}
pvalues.corr.fdr<-p.adjust(pvalues, method = "fdr", n = length(pvalues))
pvalues.corr.fdr
```

#### vegan::adonis

```{r}
comm.ads <- adonis(community_now ~ habitat_now$Habitat, method = "jaccard", perm = 999)
comm.ads
```

```{r}
comm_NF_BB.ads <- adonis(community_now_NF_BB ~ habitat_now_NF_BB$Habitat, method = "jaccard", perm = 999)
comm_NF_BB.ads
```


